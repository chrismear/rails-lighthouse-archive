diff --git a/railties/lib/rails/commands/plugin.rb b/railties/lib/rails/commands/plugin.rb
index 159db70..5947426 100644
--- a/railties/lib/rails/commands/plugin.rb
+++ b/railties/lib/rails/commands/plugin.rb
@@ -119,7 +119,7 @@ class Plugin
   
   def initialize(uri, name = nil)
     @uri = uri
-    guess_name(uri)
+    @name = guess_name(uri)
   end
   
   def self.find(name)
@@ -145,6 +145,8 @@ class Plugin
   
   def install(method=nil, options = {})
     method ||= rails_env.best_install_method?
+    @name = options[:name] || @name
+    puts "Chosen name of plugin is #{@name}" if $verbose
     if :http == method
       method = :export if svn_url?
       method = :git    if git_url?
@@ -262,11 +264,12 @@ class Plugin
     end
 
     def guess_name(url)
-      @name = File.basename(url)
-      if @name == 'trunk' || @name.empty?
-        @name = File.basename(File.dirname(url))
+      base_url = url.gsub(/(\?|#)(.*)$/, '')
+      name = File.basename(base_url)
+      if name == 'trunk' || name.empty?
+        name = File.basename(File.dirname(base_url))
       end
-      @name.gsub!(/\.git$/, '') if @name =~ /\.git$/
+      name.gsub(/\.git$/, '')
     end
     
     def rails_env
@@ -370,6 +373,8 @@ module Commands
         o.define_head "Install one or more plugins."
         o.separator   ""
         o.separator   "Options:"
+        o.on(         "-n NAME", "--name NAME",
+                      "Name of plugin. Default is name of the last directory of uri.") { |v| @options[:name] = v }
         o.on(         "-x", "--externals", 
                       "Use svn:externals to grab the plugin.", 
                       "Enables plugin updates and plugin versioning.") { |v| @method = :externals }
@@ -476,7 +481,12 @@ class RecursiveHTTPFetcher
   def initialize(urls_to_fetch, level = 1, cwd = ".")
     @level = level
     @cwd = cwd
-    @urls_to_fetch = RUBY_VERSION >= '1.9' ? urls_to_fetch.lines : urls_to_fetch.to_a
+    @urls_to_fetch = (RUBY_VERSION >= '1.9' ?
+        urls_to_fetch.lines : urls_to_fetch.to_a).map |u|
+          u = split_base_and_fragment(u)
+          u[0] << '/' unless u[0][-1].chr == '/'
+          u.join
+        }
     @quiet = false
   end
 
@@ -501,35 +511,49 @@ class RecursiveHTTPFetcher
     @cwd = File.dirname(@cwd)
   end
 
+  # Split a URI into a [base, fragment] pair
+  # where fragment is everything after the first ? or #.
+  def split_base_and_fragment(uri)
+    uri.match(/^(.*?)([?#].*)?$/)[1..-1] # (.*?) is a non-greedy match
+  end
+
+  def extract_file_name(uri)
+    File.basename(split_base_and_fragment(uri)[0])
+  end
+
   def links(base_url, contents)
     links = []
     contents.scan(/href\s*=\s*\"*[^\">]*/i) do |link|
       link = link.sub(/href="/i, "")
       next if link =~ /svnindex.xsl$/
       next if link =~ /^(\w*:|)\/\// || link =~ /^\./
-      links << File.join(base_url, link)
+      links << File.join(split_base_and_fragment(base_url)[0], link)
     end
     links
   end
   
   def download(link)
-    puts "+ #{File.join(@cwd, File.basename(link))}" unless @quiet
+    file_name = extract_file_name(link)
+    puts "Downloading file #{link}" if $verbose
+    puts "+ #{File.join(@cwd, file_name)}" unless @quiet
     open(link) do |stream|
-      File.open(File.join(@cwd, File.basename(link)), "wb") do |file|
+      File.open(File.join(@cwd, file_name), "wb") do |file|
         file.write(stream.read)
       end
     end
   end
-  
+
   def fetch(links = @urls_to_fetch)
     links.each do |l|
-      (l =~ /\/$/ || links == @urls_to_fetch) ? fetch_dir(l) : download(l)
+      stripped = split_base_and_fragment(l)[0]
+      (stripped =~ /\/$/) ? fetch_dir(l) : download(l)
     end
   end
-  
+
   def fetch_dir(url)
     @level += 1
-    push_d(File.basename(url)) if @level > 0
+    push_d(extract_file_name(url)) if @level > 0
+    puts "fetching directory #{url}" if $verbose
     open(url) do |stream|
       contents =  stream.read
       fetch(links(url, contents))
